# -*- coding: utf-8 -*-
"""lab3_ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pfZtubadjkdo0XSU9UPbnNzk5rc-r4K_
"""

import numpy as np
import pandas as pd
import pickle
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

size = 300
X = np.random.rand(size) * 5 - 2.5
w4, w3, w2, w1, w0 = 1, 2, 1, -4, 2
y = w4 * (X ** 4) + w3 * (X ** 3) + w2 * (X ** 2) + w1 * X + w0 + np.random.randn(size) * 8 - 4
df = pd.DataFrame({'x': X, 'y': y})
df.to_csv('dane_do_regresji.csv', index=None)

X = X.reshape(-1, 1)
y = y.reshape(-1, 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression
X_range = np.linspace(-2.5, 2.5, 300).reshape(-1, 1)

lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

a = lin_reg.coef_
b = lin_reg.intercept_
print(a, b)

plt.scatter(X, y, color = 'blue', label = 'Dane')
plt.plot(X_range, a*X_range + b, color = 'red', label = 'Regresja liniowa')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()

import sklearn.neighbors
X_range = np.linspace(-2.5, 2.5, 300).reshape(-1, 1)


knn_reg_3 = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)
knn_reg_3.fit(X_train, y_train)
plt.clf()
plt.plot(X_range, knn_reg_3.predict(X_range), color = 'red', label = 'Regresja k - 3 najbliższych sąsiadów')
plt.scatter(X, y, color = 'blue', label = 'Dane')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()


knn_reg_5 = sklearn.neighbors.KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train, y_train)
plt.clf()
plt.scatter(X, y, color = 'blue', label = 'Dane')
plt.plot(X_range, knn.predict(X_range), color = 'red', label = 'Regresja k - 5 najbliższych sąsiadów')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()

poly_2 = make_pipeline(PolynomialFeatures(2), LinearRegression())
poly_2.fit(X_train, y_train)

poly_3 = make_pipeline(PolynomialFeatures(3), LinearRegression())
poly_3.fit(X_train, y_train)

poly_4 = make_pipeline(PolynomialFeatures(4), LinearRegression())
poly_4.fit(X_train, y_train)

poly_5 = make_pipeline(PolynomialFeatures(5), LinearRegression())
poly_5.fit(X_train, y_train)

X_plot = np.linspace(-2.5, 2.5, 100).reshape(-1, 1)
plt.scatter(X, y, color='gray', alpha=0.5, label='Dane')
plt.plot(X_plot, poly_2.predict(X_plot), label='Stopień 2')
plt.plot(X_plot, poly_3.predict(X_plot), label='Stopień 3')
plt.plot(X_plot, poly_4.predict(X_plot), label='Stopień 4')
plt.plot(X_plot, poly_5.predict(X_plot), label='Stopień 5')
plt.legend()
plt.xlabel('x')
plt.ylabel('y')
plt.title('Regresja wielomianowa')
plt.show()

mse_values = {
    'poly_2_reg': [mean_squared_error(y_train, poly_2.predict(X_train)), mean_squared_error(y_test, poly_2.predict(X_test))],
    'poly_3_reg': [mean_squared_error(y_train, poly_3.predict(X_train)), mean_squared_error(y_test, poly_3.predict(X_test))],
    'poly_4_reg': [mean_squared_error(y_train, poly_4.predict(X_train)), mean_squared_error(y_test, poly_4.predict(X_test))],
    'poly_5_reg': [mean_squared_error(y_train, poly_5.predict(X_train)), mean_squared_error(y_test, poly_5.predict(X_test))]
}

print(mse_values)

mse_df = pd.DataFrame(mse_values, index=['train_mse', 'test_mse']).T
mse_df.to_pickle('mse.pkl')

regressors = [(poly_2, PolynomialFeatures(2)), (poly_3, PolynomialFeatures(3)), (poly_4, PolynomialFeatures(4)), (poly_5, PolynomialFeatures(5))]
with open('reg.pkl', 'wb') as f:
    pickle.dump(regressors, f)